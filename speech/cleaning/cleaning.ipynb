{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hd7OzNTCE0Z",
        "outputId": "f32c4fa5-527a-4b19-81a6-2ff23b4b5846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy --quiet\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "PrNXUY-iCyag"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "custom_stopwords = {\n",
        "    \"the\", \"and\", \"to\", \"of\", \"in\", \"that\", \"we\", \"for\", \"is\", \"on\", \"out\", \"with\",\n",
        "    \"as\", \"by\", \"at\", \"from\", \"be\", \"this\", \"it\", \"are\", \"or\", \"an\", \"way\", \"have\",\n",
        "    \"not\", \"our\", \"which\", \"has\", \"but\", \"they\", \"their\", \"was\", \"a\", \"will\",\n",
        "    \"i\", \"you\", \"he\", \"she\", \"his\", \"her\", \"its\", \"them\", \"what\", \"when\", \"where\",\n",
        "    \"how\", \"who\", \"been\", \"if\", \"do\", \"did\", \"so\", \"can\", \"would\", \"should\",\n",
        "    \"weve\", \"wont\", \"theres\", \"dont\", \"doesnt\", \"didnt\", \"isnt\", \"wasnt\", \"arent\", \"havent\",\n",
        "    \"youre\", \"youve\", \"youll\", \"hes\", \"shes\", \"theyre\", \"theyll\", \"theyd\", \"lets\",\n",
        "    \"also\", \"could\", \"may\", \"might\", \"must\", \"shall\", \"still\", \"yet\", \"even\", \"have\",\n",
        "    \"upon\", \"among\", \"within\", \"without\", \"thus\", \"therefore\", \"however\", \"though\", \"because\",\n",
        "    \"towards\", \"toward\", \"like\", \"around\", \"about\", \"between\", \"against\", \"through\",\n",
        "    \"said\", \"say\", \"says\", \"mr\", \"mrs\", \"one\", \"two\", \"three\", \"many\", \"much\", \"become\",\n",
        "    \"every\", \"each\", \"such\", \"some\", \"any\", \"all\", \"more\", \"most\", \"very\", \"year\",\n",
        "    \"just\", \"make\", \"made\", \"get\", \"got\", \"go\", \"went\", \"come\", \"came\", \"whole\",\n",
        "    \"see\", \"seen\", \"look\", \"looked\", \"want\", \"wanted\", \"use\", \"used\", \"other\",\n",
        "    \"comrade\", \"chairman\", \"great\", \"country\", \"kim\", \"speech\", \"dear\", \"people\",\n",
        "    \"party\", \"work\", \"build\", \"national\", \"day\", \"under\",\n",
        "    \"construction\", \"official\", \"nation\", \"develop\",\n",
        "    \"leader\", \"force\", \"effort\", \"life\", \"struggle\", \"new\", \"spirit\", \"into\",\n",
        "    \"korean\", \"sung\", \"high\", \"state\", \"give\", \"after\",\n",
        "    \"cause\", \"organization\", \"world\", \"carry\", \"ideological\", \"education\",\n",
        "    \"sector\", \"victory\", \"policy\", \"president\", \"take\", \"worker\", \"work\",\n",
        "    \"improve\", \"time\", \"unity\", \"powerful\", \"idea\", \"well\", \"only\", \"good\",\n",
        "    \"defend\"\n",
        "}\n",
        "\n",
        "\n",
        "def clean_text_spacy(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "\n",
        "        if (\n",
        "            token.is_alpha and\n",
        "            token.text not in custom_stopwords and\n",
        "            len(token.text) > 2\n",
        "        ):\n",
        "            tokens.append(token.lemma_)\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df = pd.read_csv(\"/content/speeches_final .csv\")\n",
        "\n",
        "\n",
        "df[\"Cleaned_Speech_Text\"] = df[\"Speech Text\"].apply(clean_text_spacy)\n",
        "\n",
        "df.to_csv(\"/content/cleaned_speeches_spacy.csv\", index=False)\n",
        "\n",
        "print(\"Очистка завершена! Результат сохранён в cleaned_speeches_spacy.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_2-3iw7DAaT",
        "outputId": "a30daa8d-8167-41e3-de99-677ecb720cba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Очистка завершена! Результат сохранён в cleaned_speeches_spacy.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "custom_stopwords = {\n",
        "    \"the\", \"and\", \"to\", \"of\", \"in\", \"that\", \"we\", \"for\", \"is\", \"on\", \"out\", \"with\",\n",
        "    \"as\", \"by\", \"at\", \"from\", \"be\", \"this\", \"it\", \"are\", \"or\", \"an\", \"way\", \"have\",\n",
        "    \"not\", \"our\", \"which\", \"has\", \"but\", \"they\", \"their\", \"was\", \"a\", \"will\",\n",
        "    \"i\", \"you\", \"he\", \"she\", \"his\", \"her\", \"its\", \"them\", \"what\", \"when\", \"where\",\n",
        "    \"how\", \"who\", \"been\", \"if\", \"do\", \"did\", \"so\", \"can\", \"would\", \"should\",\n",
        "    \"weve\", \"wont\", \"theres\", \"dont\", \"doesnt\", \"didnt\", \"isnt\", \"wasnt\", \"arent\", \"havent\",\n",
        "    \"youre\", \"youve\", \"youll\", \"hes\", \"shes\", \"theyre\", \"theyll\", \"theyd\", \"lets\",\n",
        "    \"also\", \"could\", \"may\", \"might\", \"must\", \"shall\", \"still\", \"yet\", \"even\", \"have\",\n",
        "    \"upon\", \"among\", \"within\", \"without\", \"thus\", \"therefore\", \"however\", \"though\", \"because\",\n",
        "    \"towards\", \"toward\", \"like\", \"around\", \"about\", \"between\", \"against\", \"through\",\n",
        "    \"said\", \"say\", \"says\", \"mr\", \"mrs\", \"one\", \"two\", \"three\", \"many\", \"much\", \"become\",\n",
        "    \"every\", \"each\", \"such\", \"some\", \"any\", \"all\", \"more\", \"most\", \"very\", \"year\",\n",
        "    \"just\", \"make\", \"made\", \"get\", \"got\", \"go\", \"went\", \"come\", \"came\", \"whole\",\n",
        "    \"see\", \"seen\", \"look\", \"looked\", \"want\", \"wanted\", \"use\", \"used\", \"other\",\n",
        "    \"comrade\", \"chairman\", \"great\", \"country\", \"kim\", \"speech\", \"dear\", \"people\",\n",
        "    \"work\", \"build\", \"national\", \"day\", \"under\",\n",
        "    \"construction\", \"official\", \"develop\",\n",
        "    \"idea\", \"time\", \"unity\", \"powerful\", \"well\", \"only\", \"good\",\n",
        "    \"korean\", \"high\", \"state\", \"give\", \"after\",\n",
        "    \"cause\", \"organization\", \"world\", \"carry\", \"ideological\", \"education\",\n",
        "    \"sector\", \"policy\", \"president\", \"take\", \"worker\", \"work\",\n",
        "    \"improve\", \"line\", \"economic\", \"development\", \"lead\"\n",
        "}\n",
        "\n",
        "important_words = {\n",
        "    \"revolutionary\", \"revolution\", \"juche\", \"army\", \"military\", \"socialism\", \"socialist\",\n",
        "    \"force\", \"effort\", \"leader\", \"leadership\", \"war\", \"soldier\", \"defend\", \"imperialist\",\n",
        "    \"struggle\", \"victory\", \"power\", \"nuclear\", \"enemy\", \"defense\", \"threat\", \"security\"\n",
        "}\n",
        "\n",
        "\n",
        "custom_stopwords = custom_stopwords - important_words\n",
        "\n",
        "def clean_text_spacy(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        if (\n",
        "            token.is_alpha and\n",
        "            token.text not in custom_stopwords and\n",
        "            len(token.text) > 2\n",
        "        ):\n",
        "            tokens.append(token.lemma_)\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/speeches_final .csv\")\n",
        "\n",
        "df[\"Cleaned_Speech_Text\"] = df[\"Speech Text\"].apply(clean_text_spacy)\n",
        "\n",
        "\n",
        "df.to_csv(\"/content/cleaned_speeches_soft.csv\", index=False)\n",
        "\n",
        "print(\"Мягкая очистка завершена! Результат сохранён в cleaned_speeches_soft.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw4-OSQCLJfe",
        "outputId": "23fdcefc-96dd-456f-f1c3-d018cd5e4f41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мягкая очистка завершена! Результат сохранён в cleaned_speeches_soft.csv\n"
          ]
        }
      ]
    }
  ]
}